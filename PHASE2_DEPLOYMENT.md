# Phase 2 - Deepgram ASR Integration: Deployment Guide

## âœ… What Was Implemented

Phase 2 adds real-time speech recognition to your call agent using Deepgram ASR.

### Changes Made:
1. âœ… Added `deepgram-sdk==3.8.3` to requirements.txt
2. âœ… Updated `config.py` with `deepgram_api_key` setting
3. âœ… Integrated Deepgram WebSocket in `twilio.py`:
   - Connects to Deepgram's live transcription API
   - Streams Î¼-law audio directly (no conversion needed!)
   - Receives real-time transcriptions with confidence scores
   - Logs transcripts as they arrive
   - Shows full conversation summary at call end
4. âœ… Updated k8s deployment to use secrets for API keys
5. âœ… Created helper script to create k8s secret from .env

---

## ğŸš€ Deployment Steps

### Step 1: Create Kubernetes Secret

This loads your API keys from `.env` into a k8s secret:

```bash
cd /home/adggda/gymgym
./create_k8s_secret.sh
```

**Expected output:**
```
ğŸ” Creating Kubernetes secret from .env file...
âœ… Secret created/updated successfully!
```

### Step 2: Deploy Updated Code

Run the existing deploy script which will:
- Build new Docker image with deepgram-sdk
- Load into k3s
- Restart deployment (which will pick up the secrets)

```bash
cd /home/adggda/gymgym
./deploy.sh
```

**Expected output:**
```
ğŸ—ï¸  Building Docker image...
ğŸ’¾ Saving image to tar...
ğŸ“¦ Loading into k3s...
ğŸ”„ Restarting deployment...
â³ Waiting for rollout...
âœ… Deployment complete!
```

### Step 3: Verify Deployment

Check that the pod is running and has the secrets:

```bash
# Check pod status
kubectl get pods -l app=gym-call-agent

# Check logs for startup messages
kubectl logs deployment/gym-call-agent --tail=50

# Should see:
# INFO:     Started server process
# INFO:     Waiting for application startup.
# INFO:     Application startup complete.
```

---

## ğŸ§ª Testing Phase 2

### Test 1: Make a Call to Your Own Phone

```bash
cd /home/adggda/gymgym
python test_outbound_call.py +1YOUR_PHONE "Deepgram Test"
```

### Test 2: Watch Logs in Real-Time

In another terminal:

```bash
kubectl logs deployment/gym-call-agent -f
```

### Test 3: Talk and Verify Transcriptions

1. Answer the call
2. Say something like: "Hello, this is a test call"
3. Watch the logs for transcription output

**Expected log output:**
```
ğŸ“ Stream started
âœ… Deepgram live transcription started
ğŸ—£ï¸  Speech segment detected! Level=0.156, Segment #1
ğŸ¤ Transcription [0.95]: Hello, this is a test call
ğŸ—£ï¸  Speech segment detected! Level=0.142, Segment #2
ğŸ¤ Transcription [0.87]: How can I help you today?
...
ğŸ›‘ Stream stopped
ğŸ“Š CALL STATISTICS
...
ğŸ“ TRANSCRIPTION SUMMARY
Total transcriptions: 5
Full conversation:
  [1] âœ“ Hello, this is a test call
  [2] âœ“ How can I help you today?
  [3] ... Um, let me check
  [4] âœ“ Yes, we're open
  [5] âœ“ Thanks for calling
```

---

## ğŸ¯ What to Look For

### Success Indicators:
- âœ… `âœ… Deepgram live transcription started` in logs
- âœ… `ğŸ¤ Transcription [confidence]: text` messages appear
- âœ… Transcriptions match what was said on the call
- âœ… `ğŸ“ TRANSCRIPTION SUMMARY` shows full conversation

### Potential Issues:

**Issue 1: "DEEPGRAM_API_KEY not set"**
```
âš ï¸  DEEPGRAM_API_KEY not set - transcription disabled
```
**Fix:** Run `./create_k8s_secret.sh` and redeploy

**Issue 2: "Failed to initialize Deepgram"**
```
âŒ Failed to initialize Deepgram: [error details]
```
**Fix:** Check Deepgram API key is valid, verify you have credits

**Issue 3: No transcriptions appear**
- Check that you're actually speaking (audio level should show > 0.02)
- Verify Deepgram connection started successfully
- Check for Deepgram errors in logs

---

## ğŸ“Š What Phase 2 Gives You

### Before Phase 2:
- âœ… Audio streaming works
- âœ… Can detect speech vs silence
- âŒ No idea what's being said

### After Phase 2:
- âœ… Audio streaming works
- âœ… Can detect speech vs silence
- âœ… **Real-time transcription of conversation**
- âœ… Full text of what gym employee says
- âœ… Confidence scores for each transcription
- âœ… Ready for LLM integration (Phase 3)

---

## ğŸ”œ Next Phase

**Phase 3: LLM Integration**
- Take transcriptions from Deepgram
- Send to GPT-4o-mini
- Generate intelligent responses
- Extract structured data (pricing, hours, etc.)

Once Phase 2 is working and you can see transcriptions, say:
**"Let's implement Phase 3 - add LLM logic to respond intelligently"**

---

## ğŸ’¡ Key Technical Details

### Why Î¼-law Direct Streaming Works:
- Deepgram natively supports Î¼-law encoding
- No need to convert to PCM first (saves CPU)
- Lower latency (no conversion overhead)
- Configured with: `encoding="mulaw"`, `sample_rate=8000`

### Interim Results:
- Set `interim_results=True` to get partial transcriptions
- Shows "..." for partial, "âœ“" for final
- Useful for real-time responsiveness in future phases

### Transcription Flow:
```
Twilio â†’ Î¼-law audio â†’ Your Server â†’ Deepgram WebSocket
                                          â†“
                                    Transcription events
                                          â†“
                                    Logged & stored
                                          â†“
                                    Summary at call end
```

---

*Phase 2 Complete: Speech Recognition âœ…*
*Next: Phase 3 - LLM Integration*

